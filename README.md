# Attn2Graph: From Attention Mechanisms to Graph Attention Networks (GAT)


A step-by-step exploration of attention mechanisms, their role in Transformers, and extension to Graph Neural Networks (GAT). This repo covers implementations from scratch, tutorials, and applications.

![GitHub](https://img.shields.io/badge/Python-3.8%2B-blue)
![GitHub](https://img.shields.io/badge/Framework-PyTorch/Lightning-red)
![GitHub](https://img.shields.io/badge/License-MIT-green)

---

## Topics

- Self-Attention Mechanism
- Multi-Head Attention
- Positional Encoding
- Encoder-Decoder Architecture
- Implementing Transformer for:
  - Text classification
  - Sequence-to-sequence translation
  - Language modeling

---


