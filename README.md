# Transformers from Scratch

This repository is a hands-on learning guide to understand and implement Transformer architectures from scratch using PyTorch.

---

## Topics

- Self-Attention Mechanism
- Multi-Head Attention
- Positional Encoding
- Encoder-Decoder Architecture
- Implementing Transformer for:
  - Text classification
  - Sequence-to-sequence translation
  - Language modeling

---


